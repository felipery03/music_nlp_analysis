{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob as tb\n",
    "import langid\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import RSLPStemmer\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orengo(song):\n",
    "    st = RSLPStemmer()\n",
    "    words = filter(lambda x: len(x)>0, song)\n",
    "    word_list = list(map(lambda x: st.stem(x), words))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(doc):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    new_doc = list(filter(lambda x: x not in stopwords, doc))\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\data\\dataset_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes compilations\n",
    "df = df[(df.artist != '/colecao-amo-voce/')&(df.artist != '/corinhos-infantis/')&(df.artist != '/corinhos-evangelicos/')&\n",
    "        (df.artist != '/harpa-crista/')&(df.artist != '/hinos/')&(df.artist != '/musicas-catolicas/')&(df.artist != '/musicas-gospel/')&\n",
    "        (df.artist != '/pineapple/')&(df.artist != '/umbanda/')&(df.artist != '/alok/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes artists with less than 25 songs\n",
    "df = df[(df.artist != '/melim/')&(df.artist != '/kell-smith/')&(df.artist != '/midiam-lima/')&(df.artist != '/isadora-pompeo/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleansing\n",
    "df['lyrics'] = df['lyrics'].str.strip('<div data-plugin=\"\"googleTranslate\"\" id=\"\"lyrics\"\">')\n",
    "df['lyrics'] = df['lyrics'].str.strip('<img alt=\"Instrumental\" class=\"instrumental-icon\" src=\"/img/etc/instrumental.png\"/')\n",
    "df['lyrics'] = df['lyrics'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['lyrics'] = df['lyrics'].str.replace('\\n', ' ')\n",
    "#df['lyrics'] = df['lyrics'].str.replace('\\r', '')\n",
    "df['lyrics'] = df['lyrics'].apply(lambda x: re.sub('[0-9!,.;:\\]?}{()\"[\"|@#$%*]', \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_addr = 'dicionario1.txt'\n",
    "dicionario = {}\n",
    "t = Translator()\n",
    "\n",
    "# translate phrase words to pt\n",
    "# avoid due to excedent use of google requisitions (limited to 1000/day)\n",
    "def get_pt(frase, vizinhanca):\n",
    "    fraseretorno = \"\"\n",
    "    split_frase = frase.split(\" \")\n",
    "    for x in range (0, len(split_frase)):\n",
    "        palavra = split_frase[x]\n",
    "        if(len(palavra)>2):                 #function only works for words with len>2\n",
    "            if(check_isLanguage(palavra)):      #checks if word and phrase are same language\n",
    "                fraseretorno+=palavra\n",
    "            else:                           #not same language\n",
    "                fraseretorno+=getFinalword(split_frase,x,vizinhanca)\n",
    "        else:\n",
    "            fraseretorno+=palavra\n",
    "        fraseretorno+=\" \"\n",
    "    return fraseretorno\n",
    "\n",
    "def check_isLanguage(palavra):\n",
    "    lang_palavra = t.detect(palavra).lang\n",
    "    if(lang_palavra != \"pt\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def getFinalword(vetor_frase, palavra_position, neighborhood_size):       #check with neighborhood and gives final word\n",
    "    menor, maior = calculo_neighborhood(vetor_frase,palavra_position, neighborhood_size)\n",
    "    frasefinal = \"\"\n",
    "    for i in range (menor, maior+1):\n",
    "        frasefinal+= \" \" + vetor_frase[palavra_position+i]\n",
    "    #frasefinaltb = tb(frasefinal)\n",
    "    lang_frasefinal = t.detect(frasefinal).lang\n",
    "    if(lang_frasefinal != \"pt\"):\n",
    "        try:\n",
    "            return pt_dictionary(vetor_frase[palavra_position], lang_frasefinal)\n",
    "            #palavratb = tb(vetor_frase[palavra_position])\n",
    "            #return str(palavratb.translate(to=\"pt\"))\n",
    "        except:\n",
    "            #print('deu ruim)\n",
    "            return vetor_frase[palavra_position]\n",
    "    return vetor_frase[palavra_position]\n",
    "\n",
    "\n",
    "def pt_dictionary(palavra, lang):\n",
    "    if palavra in dicionario:\n",
    "        print(palavra + \": já está no dic!\")\n",
    "        return dicionario[palavra]\n",
    "    else:\n",
    "        #palavratb = tb(palavra)\n",
    "        #print(\"traduzir para colocar no dic \" + palavra)\n",
    "        traducao = t.translate(palavra, src=lang, dest='pt').text #str(palavratb.translate(from_lang=lang,to=\"pt\"))\n",
    "        #print(\"traduzido \" + palavra + \" para \" + traducao)\n",
    "        dicionario[palavra] = traducao\n",
    "        add_dicionario(dicionario_addr,palavra)\n",
    "        print(palavra + \": adicionado ao dic!\")\n",
    "        return traducao\n",
    "\n",
    "def calculo_neighborhood(vetor_frase, palavra_position,neighborhood_size):\n",
    "    menor = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position-i >= 0:\n",
    "            menor = -i\n",
    "            break\n",
    "    maior = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position+i < len(vetor_frase):\n",
    "            maior = i\n",
    "            break\n",
    "    return menor, maior\n",
    "\n",
    "def load_dicionario(arquivo):\n",
    "    if os.path.exists(arquivo):\n",
    "        fl = open(arquivo, \"r\", encoding='utf-8')\n",
    "        for line in fl.readlines():\n",
    "            palavra, traducao = line.split(':')\n",
    "            dicionario[palavra] = traducao\n",
    "        fl.close()\n",
    "    else:\n",
    "        fl = open(arquivo, 'w+')\n",
    "\n",
    "def add_dicionario(arquivo, chave):\n",
    "    if os.path.exists(arquivo):\n",
    "        f = open(arquivo,'a', encoding='utf-8')\n",
    "    else:\n",
    "        f = open(arquivo, 'w+',encoding='utf-8')\n",
    "    f.write(chave +\":\"+ dicionario[chave]+\"\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(song):\n",
    "    import time\n",
    "    verses = song.split('\\n')\n",
    "    translated_verses = list(map(lambda x: get_pt(x,1), verses))\n",
    "    full_song = \"\".join(translated_verses)\n",
    "    print(full_song)\n",
    "    time.sleep(1)\n",
    "    return full_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-32443da47305>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-32443da47305>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-b7019474cc17>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(song)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mverses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtranslated_verses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfull_song\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated_verses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_song\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b7019474cc17>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mverses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtranslated_verses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfull_song\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated_verses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_song\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-313680e528e8>\u001b[0m in \u001b[0;36mget_pt\u001b[1;34m(frase, vizinhanca)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpalavra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_frase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                 \u001b[1;31m#function only works for words with len>2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_isLanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m      \u001b[1;31m#checks if word and phrase are same language\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mfraseretorno\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m                           \u001b[1;31m#not same language\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-313680e528e8>\u001b[0m in \u001b[0;36mcheck_isLanguage\u001b[1;34m(palavra)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_isLanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mlang_palavra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang_palavra\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;31m# actual source language that will be recognized by Google Translator when the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36m_translate\u001b[1;34m(self, text, dest, src)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googletrans\\utils.py\u001b[0m in \u001b[0;36mformat_json\u001b[1;34m(original)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlegacy_format_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googletrans\\utils.py\u001b[0m in \u001b[0;36mlegacy_format_json\u001b[1;34m(original)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnxt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "df['translated'] = df['lyrics'].apply(lambda x: translate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates new df where the column lyrics carries every song of a given artist\n",
    "df1 = df.groupby('artist')['lyrics'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applies stemmer and creates new column\n",
    "df1['orengo'] = df1['lyrics'].apply(lambda x: orengo(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes stopwords and creates new column\n",
    "df1['no_stopwords'] = df1['lyrics'].apply(lambda x: remove_stopwords(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes stopwords from translated text and creates new column\n",
    "df1['ns_pt'] = df1['translated'].apply(lambda x: remove_stopwords(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary\n",
    "df1['unique'] = df1['lyrics'].apply(lambda x: len(set(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary after stemming\n",
    "df1['orengo_unique'] = df1['orengo'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords\n",
    "df1['ns_unique'] = df1['no_stopwords'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords after stemming\n",
    "df1['ns_orengo_unique'] = df1['no_stopwords'].apply(lambda x: len(set(orengo(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary after translation\n",
    "df1['unique_pt'] = df['translated'].apply(lambda x: len(set(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary after stemming + translation\n",
    "df1['orengo_pt'] = df['translated'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords (translated)\n",
    "df1['ns_uni_pt'] = df1['ns_pt'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords after stemming + translation\n",
    "df1['ns_or_pt'] = df1['ns_pt'].apply(lambda x: len(set(orengo(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>orengo</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>unique</th>\n",
       "      <th>orengo_unique</th>\n",
       "      <th>ns_unique</th>\n",
       "      <th>ns_orengo_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/aline-barros/</td>\n",
       "      <td>mestre eu preciso de um milagre transforma min...</td>\n",
       "      <td>[mestr, eu, precis, de, um, milagr, transform,...</td>\n",
       "      <td>[mestre, preciso, milagre, transforma, vida, e...</td>\n",
       "      <td>748</td>\n",
       "      <td>581</td>\n",
       "      <td>651</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/amado-batista/</td>\n",
       "      <td>ao te ver pela primeira vez eu tremi todo uma ...</td>\n",
       "      <td>[ao, te, ver, pel, prim, vez, eu, trem, tod, u...</td>\n",
       "      <td>[ver, primeira, vez, tremi, todo, coisa, tomou...</td>\n",
       "      <td>846</td>\n",
       "      <td>621</td>\n",
       "      <td>750</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ana-carolina/</td>\n",
       "      <td>eu e você não é assim tão complicado não é dif...</td>\n",
       "      <td>[eu, e, voc, não, é, assim, tão, complic, não,...</td>\n",
       "      <td>[assim, tão, complicado, difícil, perceber, , ...</td>\n",
       "      <td>776</td>\n",
       "      <td>599</td>\n",
       "      <td>686</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/anavitoria/</td>\n",
       "      <td>eu poderia acordar sem teu olhar de sono sem t...</td>\n",
       "      <td>[eu, pod, acord, sem, teu, olh, de, son, sem, ...</td>\n",
       "      <td>[poderia, acordar, olhar, sono, lábio, dono, q...</td>\n",
       "      <td>852</td>\n",
       "      <td>673</td>\n",
       "      <td>767</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/anderson-freire/</td>\n",
       "      <td>não consigo ir além do teu olhar tudo que eu c...</td>\n",
       "      <td>[não, consig, ir, além, do, teu, olh, tud, que...</td>\n",
       "      <td>[consigo, ir, além, olhar, tudo, consigo, imag...</td>\n",
       "      <td>1127</td>\n",
       "      <td>868</td>\n",
       "      <td>1025</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                             lyrics  \\\n",
       "0     /aline-barros/  mestre eu preciso de um milagre transforma min...   \n",
       "1    /amado-batista/  ao te ver pela primeira vez eu tremi todo uma ...   \n",
       "2     /ana-carolina/  eu e você não é assim tão complicado não é dif...   \n",
       "3       /anavitoria/  eu poderia acordar sem teu olhar de sono sem t...   \n",
       "4  /anderson-freire/  não consigo ir além do teu olhar tudo que eu c...   \n",
       "\n",
       "                                              orengo  \\\n",
       "0  [mestr, eu, precis, de, um, milagr, transform,...   \n",
       "1  [ao, te, ver, pel, prim, vez, eu, trem, tod, u...   \n",
       "2  [eu, e, voc, não, é, assim, tão, complic, não,...   \n",
       "3  [eu, pod, acord, sem, teu, olh, de, son, sem, ...   \n",
       "4  [não, consig, ir, além, do, teu, olh, tud, que...   \n",
       "\n",
       "                                        no_stopwords  unique  orengo_unique  \\\n",
       "0  [mestre, preciso, milagre, transforma, vida, e...     748            581   \n",
       "1  [ver, primeira, vez, tremi, todo, coisa, tomou...     846            621   \n",
       "2  [assim, tão, complicado, difícil, perceber, , ...     776            599   \n",
       "3  [poderia, acordar, olhar, sono, lábio, dono, q...     852            673   \n",
       "4  [consigo, ir, além, olhar, tudo, consigo, imag...    1127            868   \n",
       "\n",
       "   ns_unique  ns_orengo_unique  \n",
       "0        651               520  \n",
       "1        750               559  \n",
       "2        686               539  \n",
       "3        767               613  \n",
       "4       1025               801  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./data/final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
