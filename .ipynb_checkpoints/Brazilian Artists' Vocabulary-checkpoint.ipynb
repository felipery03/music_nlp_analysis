{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob as tb\n",
    "import langid\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import RSLPStemmer\n",
    "from googletrans import Translator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orengo(song):\n",
    "    st = RSLPStemmer()\n",
    "    words = filter(lambda x: len(x)>0, song)\n",
    "    word_list = list(map(lambda x: st.stem(x), words))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(doc):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    new_doc = list(filter(lambda x: x not in stopwords, doc))\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\data\\dataset_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes compilations\n",
    "df = df[(df.artist != '/colecao-amo-voce/')&(df.artist != '/corinhos-infantis/')&(df.artist != '/corinhos-evangelicos/')&\n",
    "        (df.artist != '/harpa-crista/')&(df.artist != '/hinos/')&(df.artist != '/musicas-catolicas/')&(df.artist != '/musicas-gospel/')&\n",
    "        (df.artist != '/pineapple/')&(df.artist != '/umbanda/')&(df.artist != '/alok/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes artists with less than 25 songs\n",
    "df = df[(df.artist != '/melim/')&(df.artist != '/kell-smith/')&(df.artist != '/midiam-lima/')&(df.artist != '/isadora-pompeo/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleansing\n",
    "df['lyrics'] = df['lyrics'].str.strip('<div data-plugin=\"\"googleTranslate\"\" id=\"\"lyrics\"\">')\n",
    "df['lyrics'] = df['lyrics'].str.strip('<img alt=\"Instrumental\" class=\"instrumental-icon\" src=\"/img/etc/instrumental.png\"/')\n",
    "df['lyrics'] = df['lyrics'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['lyrics'] = df['lyrics'].str.replace('\\n', ' ')\n",
    "df['lyrics'] = df['lyrics'].str.replace('\\r', '')\n",
    "df['lyrics'] = df['lyrics'].apply(lambda x: re.sub('[0-9!,.;:\\]?}{()\"[\"|@#$%*]', \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_addr = 'dicionario1.txt'\n",
    "dicionario = {}\n",
    "t = Translator()\n",
    "\n",
    "# translate phrase words to pt\n",
    "# avoid due to excedent use of google requisitions (limited to 1000/day)\n",
    "def get_pt(frase, vizinhanca):\n",
    "    fraseretorno = \"\"\n",
    "    split_frase = frase.split(\" \")\n",
    "    for x in range (0, len(split_frase)):\n",
    "        palavra = split_frase[x]\n",
    "        if(len(palavra)>2):                 #function only works for words with len>2\n",
    "            if(check_isLanguage(palavra)):      #checks if word and phrase are same language\n",
    "                fraseretorno+=palavra\n",
    "            else:                           #not same language\n",
    "                fraseretorno+=getFinalword(split_frase,x,vizinhanca)\n",
    "        else:\n",
    "            fraseretorno+=palavra\n",
    "        fraseretorno+=\" \"\n",
    "    return fraseretorno\n",
    "\n",
    "def check_isLanguage(palavra):\n",
    "    lang_palavra = t.detect(palavra).lang\n",
    "    if(lang_palavra != \"pt\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def getFinalword(vetor_frase, palavra_position, neighborhood_size):       #check with neighborhood and gives final word\n",
    "    menor, maior = calculo_neighborhood(vetor_frase,palavra_position, neighborhood_size)\n",
    "    frasefinal = \"\"\n",
    "    for i in range (menor, maior+1):\n",
    "        frasefinal+= \" \" + vetor_frase[palavra_position+i]\n",
    "    #frasefinaltb = tb(frasefinal)\n",
    "    lang_frasefinal = t.detect(frasefinal).lang\n",
    "    if(lang_frasefinal != \"pt\"):\n",
    "        try:\n",
    "            return pt_dictionary(vetor_frase[palavra_position], lang_frasefinal)\n",
    "            #palavratb = tb(vetor_frase[palavra_position])\n",
    "            #return str(palavratb.translate(to=\"pt\"))\n",
    "        except:\n",
    "            #print('deu ruim)\n",
    "            return vetor_frase[palavra_position]\n",
    "    return vetor_frase[palavra_position]\n",
    "\n",
    "\n",
    "def pt_dictionary(palavra, lang):\n",
    "    if palavra in dicionario:\n",
    "        print(palavra + \": já está no dic!\")\n",
    "        return dicionario[palavra]\n",
    "    else:\n",
    "        #palavratb = tb(palavra)\n",
    "        #print(\"traduzir para colocar no dic \" + palavra)\n",
    "        traducao = t.translate(palavra, src=lang, dest='pt').text #str(palavratb.translate(from_lang=lang,to=\"pt\"))\n",
    "        #print(\"traduzido \" + palavra + \" para \" + traducao)\n",
    "        dicionario[palavra] = traducao\n",
    "        add_dicionario(dicionario_addr,palavra)\n",
    "        print(palavra + \": adicionado ao dic!\")\n",
    "        return traducao\n",
    "\n",
    "def calculo_neighborhood(vetor_frase, palavra_position,neighborhood_size):\n",
    "    menor = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position-i >= 0:\n",
    "            menor = -i\n",
    "            break\n",
    "    maior = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position+i < len(vetor_frase):\n",
    "            maior = i\n",
    "            break\n",
    "    return menor, maior\n",
    "\n",
    "def load_dicionario(arquivo):\n",
    "    if os.path.exists(arquivo):\n",
    "        fl = open(arquivo, \"r\", encoding='utf-8')\n",
    "        for line in fl.readlines():\n",
    "            palavra, traducao = line.split(':')\n",
    "            dicionario[palavra] = traducao\n",
    "        fl.close()\n",
    "    else:\n",
    "        fl = open(arquivo, 'w+')\n",
    "\n",
    "def add_dicionario(arquivo, chave):\n",
    "    if os.path.exists(arquivo):\n",
    "        f = open(arquivo,'a', encoding='utf-8')\n",
    "    else:\n",
    "        f = open(arquivo, 'w+',encoding='utf-8')\n",
    "    f.write(chave +\":\"+ dicionario[chave]+\"\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'te'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-aeac52d04252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;31m#print(row['lyrics'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraduzindo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tradução: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\\n\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-aeac52d04252>\u001b[0m in \u001b[0;36mtraduzindo\u001b[1;34m(song)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mverses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m#print (v)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mtranslated_verses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pt2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mfull_song\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mtranslated_verses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;31m#print(\"fullsong:\" + full_song)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-aeac52d04252>\u001b[0m in \u001b[0;36mget_pt2\u001b[1;34m(frase, vizinhanca)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mfraseretorno\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m                           \u001b[1;31m#not pt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mfraseretorno\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mgetFinalword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_frase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvizinhanca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mfraseretorno\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfraseretorno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-aeac52d04252>\u001b[0m in \u001b[0;36mgetFinalword\u001b[1;34m(vetor_frase, palavra_position, neighborhood_size)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mlang_frasefinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlangid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrasefinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang_frasefinal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpt_dictionary2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvetor_frase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalavra_position\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_frasefinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvetor_frase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalavra_position\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-aeac52d04252>\u001b[0m in \u001b[0;36mpt_dictionary2\u001b[1;34m(palavra, lang)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpt_dictionary2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicionario\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdicionario\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": já está no dic!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'te'"
     ]
    }
   ],
   "source": [
    "#google for translation only\n",
    "\n",
    "\n",
    "def get_pt2(frase, vizinhanca): #vizinhanca defines the context size for the word language analysis\n",
    "    fraseretorno = \"\"\n",
    "    split_frase = frase.split(\" \")\n",
    "    for x in range (0, len(split_frase)):\n",
    "        palavra = split_frase[x].lstrip().rstrip()\n",
    "        if(len(palavra)<2):\n",
    "            fraseretorno+=palavra\n",
    "        else:\n",
    "            if(check_isLanguage2(palavra)):      #checks if word is in portuguese\n",
    "                fraseretorno+=palavra\n",
    "            else:                           #not pt\n",
    "                fraseretorno+=getFinalword(split_frase,x,vizinhanca)\n",
    "            fraseretorno+=\" \"\n",
    "    return fraseretorno\n",
    "\n",
    "def check_isLanguage2(palavra):\n",
    "    lang_palavra = langid.classify(palavra)\n",
    "    if(lang_palavra != \"pt\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def getFinalword(vetor_frase, palavra_position, neighborhood_size):       #check with neighborhood and gives final word\n",
    "    menor, maior = calculo_neighborhood(vetor_frase,palavra_position, neighborhood_size)\n",
    "    frasefinal = \"\"\n",
    "    for i in range (menor, maior+1):\n",
    "        frasefinal+= \" \" + vetor_frase[palavra_position+i]\n",
    "    lang_frasefinal = langid.classify(frasefinal)\n",
    "    if(lang_frasefinal[0] != \"pt\"):\n",
    "        return pt_dictionary2(vetor_frase[palavra_position], lang_frasefinal)\n",
    "    return vetor_frase[palavra_position]\n",
    "\n",
    "def calculo_neighborhood(vetor_frase, palavra_position,neighborhood_size):\n",
    "    menor = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position-i >= 0:\n",
    "            menor = -i\n",
    "            break\n",
    "    maior = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position+i < len(vetor_frase):\n",
    "            maior = i\n",
    "            break\n",
    "    return menor, maior\n",
    "\n",
    "def pt_dictionary2(palavra, lang):\n",
    "    if palavra in dicionario:\n",
    "        print(palavra + \": já está no dic!\")\n",
    "        return dicionario[palavra]\n",
    "    else:\n",
    "        palavratb = tb(palavra)\n",
    "        print(palavratb)\n",
    "        print(\"traduzir para colocar no dic \" + str(palavra) + \" de \" + lang[0])\n",
    "        traducao = palavra\n",
    "        try:\n",
    "            traducao = str(palavratb.translate(from_lang=lang[0],to=\"pt\"))\n",
    "            print(\"traduzido \" + palavra + \" para \" + traducao)\n",
    "            dicionario[palavra] = traducao\n",
    "            add_dicionario(dicionario_addr,palavra)\n",
    "            print(palavra + \": adicionado ao dic!\")\n",
    "            return traducao\n",
    "        except Exception as ex:\n",
    "            if(type(ex).__name__ != \"NotTranslated\"):\n",
    "                print(palavra + \" Exception: \" + type(ex).__name__ )\n",
    "                return None\n",
    "            else:\n",
    "                print(\"traduzido \" + palavra + \" para \" + traducao)\n",
    "                dicionario[palavra] = traducao\n",
    "                add_dicionario(dicionario_addr,palavra)\n",
    "                print(palavra + \": adicionado ao dic!\")\n",
    "                return traducao\n",
    "                #se nao foi erro em que traducao igual a palavra recebida\n",
    "        #traducao = t.translate(palavra, src=lang, dest='pt').text.rstrip().lstrip()\n",
    "        #traducao = \"teste\"\n",
    "        \n",
    "    \n",
    "def load_dicionario(arquivo):\n",
    "    if os.path.exists(arquivo):\n",
    "        fl = open(arquivo, \"r\", encoding='utf-8')\n",
    "        for line in fl.readlines():\n",
    "            palavra, traducao = line.split(':')\n",
    "            dicionario[palavra] = traducao\n",
    "        fl.close()\n",
    "    else:\n",
    "        fl = open(arquivo, 'w+')\n",
    "\n",
    "def add_dicionario(arquivo, chave):\n",
    "    if os.path.exists(arquivo):\n",
    "        f = open(arquivo,'a', encoding='utf-8')\n",
    "    else:\n",
    "        f = open(arquivo, 'w+',encoding='utf-8')\n",
    "    f.write(chave +\":\"+ dicionario[chave]+\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def traduzindo(song):\n",
    "    import time\n",
    "    verses = song.split('\\n')\n",
    "    full_song = \"\"\n",
    "    #print(verses)\n",
    "    for v in verses:\n",
    "        #print (v)\n",
    "        translated_verses = get_pt2(v,1)\n",
    "        full_song+=translated_verses\n",
    "    #print(\"fullsong:\" + full_song)\n",
    "    time.sleep(1)\n",
    "    return full_song\n",
    "\n",
    "df['lyrics'] = df['lyrics'].str.replace('\\n\\n', '\\n')\n",
    "\n",
    "\n",
    "dicionario_addr = 'dicionario_teste.txt' \n",
    "dicionario = {}\n",
    "t = Translator()\n",
    "langid.set_languages(['pt','es','en'])\n",
    "load_dicionario(dicionario_addr)\n",
    "#for d in dicionario:\n",
    "#    print (d + \" -> \" + dicionario[d])\n",
    "\n",
    "#palavratb = tb(\"te\")\n",
    "#trad = str(palavratb.translate(from_lang=\"en\",to=\"pt\"))\n",
    "\n",
    "#print(trad)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    #print(row['lyrics'])\n",
    "    row['translated'] = traduzindo(row['lyrics']) \n",
    "    print(\"tradução: \" + row['translated'] + \"\\n\\n\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sei bem\n",
      "o que te faz bem eu sei\n",
      "mas no fundo eu já tentei não faltou coragem\n",
      "é uma hora eu ia me tocar que você não vai mais voltar\n",
      "não receber mensagem também é mensagem\n",
      "sei que o pra sempre virou pó\n",
      "e na cabeça deu um nó mas eu tô bem consciente\n",
      "mas amei\n",
      "amei sozinho mas por dois\n",
      "me conformei que agora e não depois\n",
      "vou ter que seguir em frente\n",
      "preocupa não\n",
      "que eu não vou bater no seu portão\n",
      "preocupa não\n",
      "que não vai ver mais o meu nome nenhuma ligação\n",
      "preocupa não\n",
      "que eu vou tomar vergonha na cara\n",
      "preocupa não\n",
      "pra um bom entendedor\n",
      "meia ausência b\n",
      "tradução: sei bem o que te faz bem eu sei mas no fundo eu já tentei não faltou coragem é uma hora eu ia me tocar que você não vai mais voltar não receber mensagem também é mensagem sei que o pra sempre virou pó e na cabeça deu um nó mas eu tô bem consciente amei sozinho mas por dois me conformei que agora e não depois vou ter que seguir em frente preocupa não que eu não vou bater no seu portão preocupa não que não vai ver mais o meu nome nenhuma ligação preocupa não que eu vou tomar vergonha na cara preocupa não pra um bom entendedor meia ausência b \n",
      "foreign: 2\n",
      "\n",
      "\n",
      "a garrafa precisa do copo\n",
      "o copo precisa da mesa\n",
      "a mesa precisa de mim\n",
      "e eu preciso da cerveja\n",
      "igual eu preciso dele na minha vida\n",
      "mas quanto mais eu vou atrás mais ele pisa\n",
      "então já que é assim\n",
      "se por ele eu sofro sem pausa\n",
      "quem quiser me amar\n",
      "também vai sofrer nessa bagaça\n",
      "quem eu quero não me quer\n",
      "quem me quer não vou querer\n",
      "ninguém vai sofrer sozinho\n",
      "todo mundo vai sofrer\n",
      "quem eu quero não me quer\n",
      "quem me quer não vou querer\n",
      "ninguém vai sofrer sozinho\n",
      "todo mundo vai sof\n",
      "tradução: a garrafa precisa do copo o copo precisa da mesa a e eu preciso da cerveja igual eu preciso dele na minha vida mas quanto mais eu vou atrás mais ele pisa então já que é assim por ele eu sofro sem pausa quem quiser me amar também vai sofrer nessa bagaça quem eu quero não me quer quem me quer não vou querer ninguém vai sofrer sozinho todo mundo vai sofrer quem eu quero não me quer quem me quer não vou querer ninguém vai sofrer sozinho todo mundo vai sof \n",
      "foreign: 5\n",
      "\n",
      "\n",
      "acordei mais uma vez embriagado\n",
      "e o seu cheiro impregnado na minha roupa\n",
      "só ficou resto do seu beijo na minha boca\n",
      "você deu mole e coração entrou na forca\n",
      "a minha saudade já tinha tomado um rumo na vida\n",
      "mas desandou com a sua ligação perdida\n",
      "faltou coragem pra dizer que não\n",
      "bebi liguei parei no seu colchão\n",
      "chego apaixonada e saio arrependido\n",
      "amar por dois só me da prejuízo\n",
      "faltou coragem pra dizer que não\n",
      "bebi liguei parei no seu colchão\n",
      "chego apaixonada e saio arrependido\n",
      "amar por dois só me da prejuízo\n",
      "só me da prejuízo\n",
      "só ficou resto do seu beijo na minha boca\n",
      "você deu corda e coração entrou na forca\n",
      "a minha saudade já tinha tomado um rumo na vida\n",
      "mas desandou com a sua ligação perdida\n",
      "faltou coragem pra dizer que não\n",
      "bebi liguei parei no seu colchão\n",
      "chego apaixonada e saio arrependido\n",
      "amar por dois só me da prejuízo\n",
      "só me da prejuízo\n",
      "chego apaixonada e saio arrependido\n",
      "amar por dois só me da prejuízo\n",
      "faltou coragem pra dizer que não\n",
      "bebi liguei parei no seu colchão\n",
      "chego apaixonada e saio arrependido\n",
      "amar por dois só me da prejuíz\n",
      "tradução: acordei mais uma vez embriagado e o seu cheiro impregnado na minha roupa ficou resto do seu beijo na minha você deu mole e coração entrou na forca a minha saudade já tinha tomado um rumo na vida desandou com a sua ligação perdida faltou coragem pra dizer que não bebi liguei parei no seu colchão chego apaixonada e saio arrependido amar só me da prejuízo faltou coragem pra dizer que não bebi liguei parei no seu colchão chego apaixonada e saio arrependido amar só me da prejuízo prejuízo ficou resto do seu beijo na minha você deu corda e coração entrou na forca a minha saudade já tinha tomado um rumo na vida desandou com a sua ligação perdida faltou coragem pra dizer que não bebi liguei parei no seu colchão chego apaixonada e saio arrependido amar só me da prejuízo prejuízo chego apaixonada e saio arrependido amar só me da prejuízo faltou coragem pra dizer que não bebi liguei parei no seu colchão chego apaixonada e saio arrependido amar só me da prejuíz \n",
      "foreign: 22\n",
      "\n",
      "\n",
      "no começo eu entendia\n",
      "mas era só cama não tinha amor\n",
      "lembro quando você dizia\n",
      "vou desligar porque ela chegou\n",
      "e a gente foi se envolvendo perdendo o medo\n",
      "não tinha lugar e nem hora pra dar um beijo\n",
      "coração não tá mais aceitando\n",
      "só metade do seu te amo\n",
      "é uma ciumeira atrás da outra\n",
      "ter que dividir seu corpo e a sua boca\n",
      "tá bom que eu aceitei por um instante\n",
      "a verdade é que amante não quer ser amante\n",
      "é uma ciumeira atrás da outra\n",
      "ter que dividir seu corpo e a sua boca\n",
      "tá bom que eu aceitei por um instante\n",
      "a verdade é que amante não quer ser amante\n",
      "é uma ciumeira atrás da outra\n",
      "e a gente foi se envolvendo perdendo o medo\n",
      "não tinha lugar e nem hora pra dar um beijo\n",
      "coração não tá mais aceitando\n",
      "só metade do seu te amo\n",
      "é uma ciumeira atrás da outra\n",
      "ter que dividir seu corpo e a sua boca\n",
      "tá bom que eu aceitei por um instante\n",
      "a verdade é que amante não quer ser amante\n",
      "é uma ciumeira atrás da outra\n",
      "ter que dividir seu corpo e a sua boca\n",
      "tá bom que eu aceitei por um instante\n",
      "a verdade é que amante não quer ser amante\n",
      "é uma ciumeira atrás da outra\n",
      "ter que dividir seu corpo e a sua boca\n",
      "tá bom que eu aceitei por um instante\n",
      "a verdade é que amante não quer ser amante\n",
      "é uma ciumeira atrá\n",
      "tradução: no começo eu entendia era só cama não tinha amor lembro quando você dizia e a gente foi se envolvendo perdendo o medo não tinha lugar e nem hora pra dar um beijo coração não tá mais aceitando só metade do seu te amo é uma ciumeira atrás da outra ter que dividir seu corpo e a sua boca bom que eu aceitei por um instante a verdade é que amante não quer ser amante é uma ciumeira atrás da outra ter que dividir seu corpo e a sua boca bom que eu aceitei por um instante a verdade é que amante não quer ser amante é uma ciumeira atrás da outra e a gente foi se envolvendo perdendo o medo não tinha lugar e nem hora pra dar um beijo coração não tá mais aceitando só metade do seu te amo é uma ciumeira atrás da outra ter que dividir seu corpo e a sua boca bom que eu aceitei por um instante a verdade é que amante não quer ser amante é uma ciumeira atrás da outra ter que dividir seu corpo e a sua boca bom que eu aceitei por um instante a verdade é que amante não quer ser amante é uma ciumeira atrás da outra ter que dividir seu corpo e a sua boca bom que eu aceitei por um instante a verdade é que amante não quer ser amante é uma ciumeira atrá \n",
      "foreign: 11\n",
      "\n",
      "\n",
      "mente que vai dar uma volta e vem me ver\n",
      "entre uma briga e outra de vocês\n",
      "eu nem conheço ela mas me sinto culpada\n",
      "primeiro que eu nem devia tá aqui\n",
      "segundo cê não tinha que ligar pra mim\n",
      "mas você ligou e eu atendi\n",
      "eu penso não mas falo sim\n",
      "bem pior que eu você\n",
      "que não deixa ela e nem deixa de me ver\n",
      "bem pior que eu você\n",
      "desconta sua raiva em duas horas de prazer\n",
      "eu venho porque eu não tenho nada a perder já você\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5b2b1ef3e5c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'foreign'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoPT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tradução: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\nforeign: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'foreign'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\\n\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-5b2b1ef3e5c5>\u001b[0m in \u001b[0;36mtoPT\u001b[1;34m(song)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mcontador\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mforeign\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m#print(\"fullsong:\" + full_song)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfull_song\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontador\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#counting english and spanish words\n",
    "\n",
    "langid.set_languages(['pt', 'en', 'es'])\n",
    "\n",
    "def get_pt_only(frase, vizinhanca): #vizinhanca defines the context size for the word language analysis\n",
    "    #print(frase)\n",
    "    counter = 0\n",
    "    fraseretorno = \"\"\n",
    "    split_frase = frase.split(\" \")\n",
    "    for x in range (0, len(split_frase)):\n",
    "        palavra = split_frase[x].lstrip().rstrip()\n",
    "        #print (palavra)\n",
    "        if(check_isLanguage_pt(palavra)):      #checks if word is in portuguese\n",
    "            fraseretorno+=palavra + \" \"\n",
    "        else:\n",
    "            palavra_final=getFinallang(split_frase,x,vizinhanca)\n",
    "            if(palavra_final == palavra):\n",
    "                fraseretorno+=palavra + \" \"\n",
    "            else:\n",
    "                counter+=1\n",
    "    return fraseretorno, counter\n",
    "\n",
    "def check_isLanguage_pt(palavra):\n",
    "    lang_palavra = langid.classify(palavra)\n",
    "    #print(palavra + \" \" + lang_palavra[0])\n",
    "    if(lang_palavra[0] != \"pt\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def getFinallang(vetor_frase, palavra_position, neighborhood_size):       #check with neighborhood and gives final word\n",
    "    menor, maior = calculo_neighborhood(vetor_frase,palavra_position, neighborhood_size)\n",
    "    frasefinal = \"\"\n",
    "    for i in range (menor, maior+1):\n",
    "        frasefinal+= \" \" + vetor_frase[palavra_position+i]\n",
    "    lang_frasefinal = langid.classify(frasefinal)\n",
    "    if(lang_frasefinal[0] != \"pt\"):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return vetor_frase[palavra_position]\n",
    "    \n",
    "def calculo_neighborhood(vetor_frase, palavra_position,neighborhood_size):\n",
    "    menor = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position-i >= 0:\n",
    "            menor = -i\n",
    "            break\n",
    "    maior = 0\n",
    "    for i in range (neighborhood_size,0,-1):\n",
    "        if palavra_position+i < len(vetor_frase):\n",
    "            maior = i\n",
    "            break\n",
    "    return menor, maior\n",
    "    return vetor_frase[palavra_position]\n",
    "\n",
    "\n",
    "def toPT(song):\n",
    "    import time\n",
    "    verses = song.split('\\n')\n",
    "    contador = 0\n",
    "    full_song = \"\"\n",
    "    #print(verses)\n",
    "    for v in verses:\n",
    "        #print (v)\n",
    "        translated_verses, foreign = get_pt_only(v,3)\n",
    "        full_song+=translated_verses\n",
    "        contador+=foreign\n",
    "    #print(\"fullsong:\" + full_song)\n",
    "    time.sleep(1)\n",
    "    return full_song, contador\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row['lyrics'])\n",
    "    row['translated'], row['foreign'] = toPT(row['lyrics']) \n",
    "    print(\"tradução: \" + row['translated'] + \"\\nforeign: \" + str(row['foreign']) + \"\\n\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(song):\n",
    "    import time\n",
    "    verses = song.split('\\n')\n",
    "    translated_verses = list(map(lambda x: get_pt(x,1), verses))\n",
    "    full_song = \"\".join(translated_verses)\n",
    "    print(full_song)\n",
    "    time.sleep(1)\n",
    "    return full_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-508451f8e8fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df['translated'] = df['lyrics'].apply(lambda x: translate(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'translated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b7019474cc17>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(song)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mverses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtranslated_verses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfull_song\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated_verses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_song\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b7019474cc17>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mverses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtranslated_verses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfull_song\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated_verses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_song\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-313680e528e8>\u001b[0m in \u001b[0;36mget_pt\u001b[1;34m(frase, vizinhanca)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpalavra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_frase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                 \u001b[1;31m#function only works for words with len>2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_isLanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m      \u001b[1;31m#checks if word and phrase are same language\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mfraseretorno\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m                           \u001b[1;31m#not same language\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-313680e528e8>\u001b[0m in \u001b[0;36mcheck_isLanguage\u001b[1;34m(palavra)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_isLanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mlang_palavra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang_palavra\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;31m# actual source language that will be recognized by Google Translator when the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36m_translate\u001b[1;34m(self, text, dest, src)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\googletrans\\utils.py\u001b[0m in \u001b[0;36mformat_json\u001b[1;34m(original)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlegacy_format_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\googletrans\\utils.py\u001b[0m in \u001b[0;36mlegacy_format_json\u001b[1;34m(original)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnxt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#df['translated'] = df['lyrics'].apply(lambda x: translate(x))\n",
    "for index, row in df.iterrows():\n",
    "    row['translated'] = translate(row['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates new df where the column lyrics carries every song of a given artist\n",
    "df1 = df.groupby('artist')['lyrics'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applies stemmer and creates new column\n",
    "df1['orengo'] = df1['lyrics'].apply(lambda x: orengo(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes stopwords and creates new column\n",
    "df1['no_stopwords'] = df1['lyrics'].apply(lambda x: remove_stopwords(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes stopwords from translated text and creates new column\n",
    "df1['ns_pt'] = df1['translated'].apply(lambda x: remove_stopwords(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary\n",
    "df1['unique'] = df1['lyrics'].apply(lambda x: len(set(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary after stemming\n",
    "df1['orengo_unique'] = df1['orengo'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords\n",
    "df1['ns_unique'] = df1['no_stopwords'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords after stemming\n",
    "df1['ns_orengo_unique'] = df1['no_stopwords'].apply(lambda x: len(set(orengo(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary after translation\n",
    "df1['unique_pt'] = df['translated'].apply(lambda x: len(set(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary after stemming + translation\n",
    "df1['orengo_pt'] = df['translated'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords (translated)\n",
    "df1['ns_uni_pt'] = df1['ns_pt'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary without considering stopwords after stemming + translation\n",
    "df1['ns_or_pt'] = df1['ns_pt'].apply(lambda x: len(set(orengo(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>orengo</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>unique</th>\n",
       "      <th>orengo_unique</th>\n",
       "      <th>ns_unique</th>\n",
       "      <th>ns_orengo_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/aline-barros/</td>\n",
       "      <td>mestre eu preciso de um milagre transforma min...</td>\n",
       "      <td>[mestr, eu, precis, de, um, milagr, transform,...</td>\n",
       "      <td>[mestre, preciso, milagre, transforma, vida, e...</td>\n",
       "      <td>748</td>\n",
       "      <td>581</td>\n",
       "      <td>651</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/amado-batista/</td>\n",
       "      <td>ao te ver pela primeira vez eu tremi todo uma ...</td>\n",
       "      <td>[ao, te, ver, pel, prim, vez, eu, trem, tod, u...</td>\n",
       "      <td>[ver, primeira, vez, tremi, todo, coisa, tomou...</td>\n",
       "      <td>846</td>\n",
       "      <td>621</td>\n",
       "      <td>750</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ana-carolina/</td>\n",
       "      <td>eu e você não é assim tão complicado não é dif...</td>\n",
       "      <td>[eu, e, voc, não, é, assim, tão, complic, não,...</td>\n",
       "      <td>[assim, tão, complicado, difícil, perceber, , ...</td>\n",
       "      <td>776</td>\n",
       "      <td>599</td>\n",
       "      <td>686</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/anavitoria/</td>\n",
       "      <td>eu poderia acordar sem teu olhar de sono sem t...</td>\n",
       "      <td>[eu, pod, acord, sem, teu, olh, de, son, sem, ...</td>\n",
       "      <td>[poderia, acordar, olhar, sono, lábio, dono, q...</td>\n",
       "      <td>852</td>\n",
       "      <td>673</td>\n",
       "      <td>767</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/anderson-freire/</td>\n",
       "      <td>não consigo ir além do teu olhar tudo que eu c...</td>\n",
       "      <td>[não, consig, ir, além, do, teu, olh, tud, que...</td>\n",
       "      <td>[consigo, ir, além, olhar, tudo, consigo, imag...</td>\n",
       "      <td>1127</td>\n",
       "      <td>868</td>\n",
       "      <td>1025</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                             lyrics  \\\n",
       "0     /aline-barros/  mestre eu preciso de um milagre transforma min...   \n",
       "1    /amado-batista/  ao te ver pela primeira vez eu tremi todo uma ...   \n",
       "2     /ana-carolina/  eu e você não é assim tão complicado não é dif...   \n",
       "3       /anavitoria/  eu poderia acordar sem teu olhar de sono sem t...   \n",
       "4  /anderson-freire/  não consigo ir além do teu olhar tudo que eu c...   \n",
       "\n",
       "                                              orengo  \\\n",
       "0  [mestr, eu, precis, de, um, milagr, transform,...   \n",
       "1  [ao, te, ver, pel, prim, vez, eu, trem, tod, u...   \n",
       "2  [eu, e, voc, não, é, assim, tão, complic, não,...   \n",
       "3  [eu, pod, acord, sem, teu, olh, de, son, sem, ...   \n",
       "4  [não, consig, ir, além, do, teu, olh, tud, que...   \n",
       "\n",
       "                                        no_stopwords  unique  orengo_unique  \\\n",
       "0  [mestre, preciso, milagre, transforma, vida, e...     748            581   \n",
       "1  [ver, primeira, vez, tremi, todo, coisa, tomou...     846            621   \n",
       "2  [assim, tão, complicado, difícil, perceber, , ...     776            599   \n",
       "3  [poderia, acordar, olhar, sono, lábio, dono, q...     852            673   \n",
       "4  [consigo, ir, além, olhar, tudo, consigo, imag...    1127            868   \n",
       "\n",
       "   ns_unique  ns_orengo_unique  \n",
       "0        651               520  \n",
       "1        750               559  \n",
       "2        686               539  \n",
       "3        767               613  \n",
       "4       1025               801  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./data/final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
